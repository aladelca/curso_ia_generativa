{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0742542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3befb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"retail_store_inventory.csv\")\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493168e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable lag\n",
    "# Para cada combinación de tienda-producto, queremos la venta de hace n periodos\n",
    "\n",
    "# Primero ordenar\n",
    "# Número de periodos hacia atrás que queremos recorrer\n",
    "n = 10\n",
    "nivel_agregacion = [\"Category\", \"Region\"]\n",
    "agg_func = \"sum\"\n",
    "date_col = \"Date\"\n",
    "lag_column = \"Units Sold\"\n",
    "data[date_col] = pd.to_datetime(data[date_col])\n",
    "data[[\"Date\",\"Store ID\",\"Product ID\",\"Category\",\"Region\",\"Units Sold\"]].sort_values([\"Date\"], inplace=True)\n",
    "df = data.groupby(nivel_agregacion + [date_col]).agg(\n",
    "    {lag_column:agg_func}\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "df[\"date_lag\"] = df[\"Date\"] - pd.Timedelta(days=-n)\n",
    "df = df.drop(columns = [\"Date\"])\n",
    "label = \"_\".join(nivel_agregacion)\n",
    "df = df.rename(columns = {lag_column:f\"lag_{lag_column}_{label}_{agg_func}_{n}\"})\n",
    "df_final = data.merge(df, left_on = nivel_agregacion + [date_col], right_on = nivel_agregacion + [\"date_lag\"], how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aebbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.random.randint(10,1000,10000)\n",
    "test = np.random.randint(10,1000,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_train = np.mean(train)\n",
    "std_train = np.std(train)\n",
    "(test-media_train)/std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "esc = StandardScaler()\n",
    "esc.fit_transform(train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "esc.transform(test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7649e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Optional, Union\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class LagByGroupDateTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Crea una columna de lag del agregado de `lag_column` por (nivel_agregacion, date_col),\n",
    "    desplazando n días hacia atrás y uniendo al dataset original.\n",
    "\n",
    "    - fit: calcula y guarda la tabla de lookup de lags (NO toca X).\n",
    "    - transform: hace merge de X con la tabla de lags ya calculada (sin recomputar).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n: int = 1,\n",
    "        nivel_agregacion: List[str] = None,\n",
    "        agg_func: str = \"sum\",\n",
    "        date_col: str = \"Date\",\n",
    "        lag_column: str = \"Units Sold\",\n",
    "        ref_date: Optional[Union[str, pd.Timestamp]] = None,\n",
    "        keep_original_date: bool = True,\n",
    "    ):\n",
    "        self.n = int(n)\n",
    "        self.nivel_agregacion = nivel_agregacion \n",
    "        self.agg_func = agg_func\n",
    "        self.date_col = date_col\n",
    "        self.lag_column = lag_column\n",
    "        self.ref_date = pd.to_datetime(ref_date).normalize() if ref_date is not None else None\n",
    "        self.keep_original_date = keep_original_date\n",
    "\n",
    "    def _validate_input(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.copy()\n",
    "        if self.date_col not in X.columns:\n",
    "            raise ValueError(f\"'{self.date_col}' no está en las columnas del DataFrame.\")\n",
    "        for col in self.nivel_agregacion + [self.lag_column]:\n",
    "            if col not in X.columns:\n",
    "                raise ValueError(f\"'{col}' no está en las columnas del DataFrame.\")\n",
    "        X[self.date_col] = pd.to_datetime(X[self.date_col])\n",
    "        return X\n",
    "\n",
    "    def _build_lookup(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Agrega por grupo + fecha\n",
    "        grp = X.groupby(self.nivel_agregacion + [self.date_col], dropna=False).agg(\n",
    "            **{self.agg_func: (self.lag_column, self.agg_func)}\n",
    "        ).reset_index()\n",
    "\n",
    "        # Renombra la columna agregada al formato solicitado\n",
    "        label = \"_\".join(self.nivel_agregacion)\n",
    "        lag_feat = f\"lag_{self.lag_column}_{label}_{self.agg_func}_{self.n}\"\n",
    "\n",
    "        # Desplaza la fecha hacia ATRÁS n días para construir el join key\n",
    "        grp[\"date_lag\"] = grp[self.date_col] - pd.Timedelta(days=self.n)\n",
    "        grp = grp.rename(columns={self.agg_func: lag_feat})\n",
    "\n",
    "        # (Opcional) si se define ref_date, filtramos la parte \"base\" para evitar información futura.\n",
    "        # La lógica: solo podemos conocer el agregado hasta ref_date (inclusive),\n",
    "        # por lo que las filas cuyo 'Date' (la fecha origen del valor agregado) sea > ref_date, se descartan.\n",
    "        if self._effective_ref_date is not None:\n",
    "            grp = grp.loc[grp[self.date_col] <= self._effective_ref_date].copy()\n",
    "\n",
    "        # Nos quedamos con las columnas necesarias para el merge en transform\n",
    "        lookup_cols = self.nivel_agregacion + [\"date_lag\", lag_feat]\n",
    "        return grp[lookup_cols].sort_values(self.nivel_agregacion + [\"date_lag\"]).reset_index(drop=True)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        X = self._validate_input(X)\n",
    "\n",
    "        # ref_date efectiva: si no se pasó, tomamos hoy (normalizado a medianoche)\n",
    "        self._effective_ref_date = (\n",
    "            self.ref_date if self.ref_date is not None else pd.Timestamp.today().normalize()\n",
    "        )\n",
    "\n",
    "        # Construye y guarda la tabla lookup\n",
    "        self._lag_feature_name_ = f\"lag_{self.lag_column}_{'_'.join(self.nivel_agregacion)}_{self.agg_func}_{self.n}\"\n",
    "        self._lookup_df_ = self._build_lookup(X)\n",
    "\n",
    "        # Guarda un set de columnas para chequeos\n",
    "        self._input_columns_ = list(X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        check_is_fitted(self, attributes=[\"_lookup_df_\", \"_lag_feature_name_\"])\n",
    "        X = self._validate_input(X)\n",
    "\n",
    "        # Clonamos para no tocar el original\n",
    "        out = X.copy()\n",
    "\n",
    "        # Si se quiere, recortamos los datos de entrada a fechas que no miren al futuro\n",
    "        # respecto de la ref_date efectiva (esto evita fugas cuando te pasan fechas futuras).\n",
    "        #if self._effective_ref_date is not None:\n",
    "        #    out = out.loc[out[self.date_col] <= self._effective_ref_date].copy()\n",
    "\n",
    "        # Preparamos claves de merge: izquierda usa (nivel_agregacion + date_col),\n",
    "        # derecha usa (nivel_agregacion + \"date_lag\") para traer el valor de hace n días.\n",
    "        right_on = self.nivel_agregacion + [\"date_lag\"]\n",
    "        left_on = self.nivel_agregacion + [self.date_col]\n",
    "\n",
    "        out = out.merge(\n",
    "            self._lookup_df_, how=\"left\", left_on=left_on, right_on=right_on, sort=False\n",
    "        )\n",
    "\n",
    "        # Limpieza de columnas auxiliares\n",
    "        if not self.keep_original_date:\n",
    "            out = out.drop(columns=[self.date_col], errors=\"ignore\")\n",
    "        out = out.drop(columns=[\"date_lag\"], errors=\"ignore\")\n",
    "\n",
    "        return out\n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, y=None, **fit_params) -> pd.DataFrame:\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "    # Conveniencia\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self, attributes=[\"_lag_feature_name_\"])\n",
    "        return [self._lag_feature_name_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data[\"Date\"]<=\"2023-12-31\"]\n",
    "test = data[data[\"Date\"]>\"2023-12-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299bd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = LagByGroupDateTransformer(\n",
    "    n=1,\n",
    "    nivel_agregacion=[\"Category\", \"Region\"],\n",
    "    agg_func=\"sum\",\n",
    "    date_col=\"Date\",\n",
    "    lag_column=\"Units Sold\",\n",
    "    # ref_date opcional; si no la pones, usa \"hoy\"\n",
    "    ref_date=\"2023-12-31\"\n",
    ")\n",
    "\n",
    "# Entrenamiento (con histórico)\n",
    "tx.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx._lookup_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d93b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f68436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lag_transformer import LagByGroupDateTransformer\n",
    "\n",
    "LagByGroupDateTransformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
